---
title: 'w271: Homework 4 (Due: Week 5)'
author: "Professor Jeffrey Yau"
geometry: margin=1in
output:
  html_document:
    df_print: paged
  number_sections: yes
  pdf_document: null
  toc: yes
fontsize: 11pt
---

# Due: 4pm Pacific Time on the Day of the Live Session of Week 5

# Instructions (Please Read it Carefully!):

*  $\textbf{Page limit of the pdf report: None, but please be reasonable}$
* Page setup: 
  * Use the following font size, margin, and linespace:
    * fontsize=11pt
    * margin=1in
    * line_spacing=single

* Submission:
    * Each student submits his/her homework to the course github repo by the deadline; submission and revision made after the deadline will not be graded
    
    * Submit 2 files:
        1. A pdf file that details your answers. Include all the R codes used to produce the answers. *Please do not suppress the codes in your pdf file.*
        2. R markdown file used to produce the pdf file
    
    * Use the following file-naming convensation; fail to do so will receive $10\%$ reduction in the grade:
        * StudentFirstNameLastName_HWNumber.fileExtension
        * For example, if the student's name is Kyle Cartman for homework 1, name your files as
            * KyleCartman_HW1.Rmd
            * KyleCartman_HW1.pdf
    
    * Although it sounds obvious, please write your name on page 1 of your pdf and Rmd files.

    * For statistical methods that we cover in this course, use only the R libraries and functions that are covered in this course. If you use libraries and functions for statistical modeling that we have not covered, you have to  (1) provide an explanation of why such libraries and functions are used instead and (2) reference to the library documentation. **Lacking the explanation and reference to the documentation will result in a score of zero for the corresponding question.** For data wrangling and data visualization, you are free to use other libraries, such as dplyr, ggplot2, etc.

  * For mathematical formulae, type them in your R markdown file. **Do not write them on a piece of paper, snap a photo, and either insert the image file or sumbit the image file separately. Doing so will receive a $0$ for that whole question.**

  *  Students are expected to act with regards to UC Berkeley Academic Integrity.

\newpage
**Question 18 a and b of Chapter 3 (page 192,193)**

For the wheat kernel data (*wheat.csv*), consider a model to estimate the `kernel condition` using the `density` explanatory variable as a linear term.

## Part A

**a. Write an R function that computes the log-likelihood function for the multinomial regression model. Evaluate the function at the parameter estimates produced by `multinom()`, and verify that your computed value is the same as that produced by `logLik()` (use the object saved from `multinom()` within this function).**


**Answer:**

We are going to answer this question in a few steps. 

  1. Set up the some initial codes and loading the data. 
  
  2. Estimate the model whose specification is given by the question using the `multinom()` function and obtain the model object's components.
  
  3. Write a custom R function that computes the log-likelihood function for the multinomial regression model. 

  4. Evaluate the function at the parameter estimates produced by `multinom()`, and verify that the computed value is the same as that produced by `logLik()` (use the object saved from `multinom()` within this function).


**1. Set up the some initial codes and loading the data.**
```{r, warning=FALSE, message=FALSE}
rm(list = ls())

knitr::opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)

# Load Libraries
library(car)
library(Hmisc)
# library(skimr)
library(ggplot2)
library(stargazer)
# library(gmodels) # For cross tabulation (SAS and SPSS style)

library(MASS)
library(mcprofile)
# library(vcd)
library(nnet)

wheat <- read.csv("../wheat.csv", stringsAsFactors = FALSE, header = TRUE, sep = ",")

str(wheat)
```

**2. Estimate the model whose specification is given by the question using thge `multinom()` function and obtain the model object's components.**
```{r}
# model
nominal.fit1 <- multinom(as.factor(type) ~  density, data = wheat)
summary(nominal.fit1)

# log likelihood of fitted model
logLik(nominal.fit1)

# variance / co-variance matrix
round(vcov(nominal.fit1),2)
```


**3. Write a custom R function that computes the log-likelihood function for the multinomial regression model. 4. Evaluate the function at the parameter estimates produced by `multinom()`, and verify that the computed value is the same as that produced by `logLik()` (use the object saved from `multinom()` within this function).**

```{r}
compute.logL <- function(beta, x, y) {
  # reference pg. 152 of textbook
  den  <- 1 + exp(beta[1] + beta[3]*x) + exp(beta[2] + beta[4]*x)
  pi1  <- 1/den
  pi2  <- exp(beta[1] + beta[3]*x)/den
  pi3  <- exp(beta[2] + beta[4]*x)/den
  LogL <- sum(y[,1]*log(pi1) + y[,2]*log(pi2) + y[,3]*log(pi3))
  return(LogL)
}

# Data
healthy <- ifelse(test = wheat$type == "Healthy", yes=1, no=0)
sprout  <- ifelse(test = wheat$type == "Sprout" , yes=1, no=0)
scab    <- ifelse(test = wheat$type == "Scab"   , yes=1, no=0)
y <- cbind(healthy, scab, sprout)
x <- wheat$density
  
```

**4. Evaluate the function at the parameter estimates produced by `multinom()`, and verify that the computed value is the same as that produced by `logLik()` (use the object saved from `multinom()` within this function).**
```{r}

# Parameters estimates from multinom() are in beta.hat
beta.hat <- coef(nominal.fit1)
logL <- compute.logL(beta = beta.hat, x = x, y = y)
logL
```

## Part B

**b. Maximize the log-likelihood function using `optim()` to obtain the MLEs and the estimated covariance matrix. Compare your answers to what is obtained by `multinom()`.**

Note that to obtain starting values for `optim()`, one approach is to estimate separate logistic regression models for $log \left( \frac{\pi_2}{\pi_1} \right)$ and $log \left( \frac{\pi_3}{\pi_1} \right)$. These models are estimated only for those observations that have the corresponding responses (e.g., a $Y = 1$ or $Y = 2$ for $log \left( \frac{\pi_2}{\pi_1} \right)$).

**Answers:**

We will just initialize paramters to random instead of computing logistic regression models as the question suggests.


```{r}
# Data
healthy <- ifelse(test = wheat$type == "Healthy", yes=1, no=0)
sprout  <- ifelse(test = wheat$type == "Sprout" , yes=1, no=0)
scab    <- ifelse(test = wheat$type == "Scab"   , yes=1, no=0)
y <- cbind(healthy, scab, sprout)
x <- as.matrix(wheat$density)

# Use the optimization routine to find the estimate
opt <- optim(rnorm(4),
             compute.logL,
             x=x,
             y=y,
             control = list(fnscale = -1),
             hessian=TRUE)

# hessian matrix
hessian <- opt$hessian

# paramter updates
pars <- data.frame(matrix(opt$par, ncol=2), row.names=c('Scab', 'Sprout'))
colnames(pars) <- c('Intercept', 'density')

pars
hessian
```

**Compute the variance / co-variance matrix using Hessian matrix output...**
```{r}
vcov <- data.frame(-solve(hessian),
           row.names=c("Scab:Intercept", "Sprout:Intercept", "Scab:density", "Sprout:density"))

colnames(vcov) <- c("Scab:Intercept", "Sprout:Intercept", "Scab:density", "Sprout:density")
```

*.. as compared to the vcov output from multinom()*
```{r}
round(vcov(nominal.fit1),2)
```



